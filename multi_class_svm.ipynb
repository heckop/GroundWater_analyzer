{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "from svm import SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulticlassSVM:\n",
    "    \"\"\"Class implementing a Support Vector Machine for multi-classification purposes based on one-vs-one strategy.\n",
    "    Given N different classes to classify, the algorithm provides N*(N-1)/2 SVM binary classifiers. Each classifier is\n",
    "    trained to correctly classify 2 of the N given classes using in the training process only the entries in the\n",
    "    dataset to which it corresponds a label of the 2 classes. Given an unseen example, the prediction of the class is\n",
    "    computed deploying a voting schema among the classifiers.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    kernel : {\"linear\", \"rbf\", \"poly\", \"sigmoid\"}\n",
    "        Type of kernel function.\n",
    "    gamma : float or None, default=None\n",
    "        Value representing the gamma parameter of the kernel; if None, it will be computed automatically during fit.\n",
    "    deg : int, default=3\n",
    "        Value representing the degree of the \"poly\" kernel function.\n",
    "    r : float, default=0.\n",
    "        Value representing the r parameter of \"poly\" and \"sigmoid\" kernel functions.\n",
    "    c : float or None, default=1\n",
    "        Value regulating the trade-off between the amount of misclassified samples and the size of the margin\n",
    "        (its \"softness\" decreases as C increases); if None, hard margin is employed (no tolerance towards\n",
    "        misclassified samples).\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    _kernel : {\"linear\", \"rbf\", \"poly\", \"sigmoid\"}\n",
    "        Type of kernel function.\n",
    "    _gamma : float or None\n",
    "        Value representing the gamma parameter of the kernel; if None, it will be computed automatically during fit.\n",
    "    _deg : int\n",
    "        Value representing the degree of the \"poly\" kernel function.\n",
    "    _r : float\n",
    "        Value representing the r parameter of \"poly\" and \"sigmoid\" kernel functions.\n",
    "    _c : float or None\n",
    "        Value regulating the trade-off between the amount of misclassified samples and the size of the margin\n",
    "        (its \"softness\" decreases as C increases); if None, hard margin is employed (no tolerance towards\n",
    "        misclassified samples).\n",
    "    _svm_list : list of SVM\n",
    "        List of triplets, each one comprising the SVM binary classifier, the label of the 1st class and the label of\n",
    "        the 2nd class (1st class corresponds to sign \"-\", 2nd class corresponds to sign \"+\"); the number of binary\n",
    "        SVM classifiers needed will be known only when the dataset labels are given.\n",
    "    _labels : ndarray or None\n",
    "        Integer labels.\n",
    "    _support_vectors : set of tuple of (float, float)\n",
    "        Set of support vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            kernel: str = \"linear\",\n",
    "            gamma: float | None = None,\n",
    "            deg: int = 3,\n",
    "            r: float = 0.,\n",
    "            c: float | None = 1.\n",
    "    ):\n",
    "        # By default linear kernel is used\n",
    "        self._kernel = kernel\n",
    "        # If gamma is None, it will be computed during fit process\n",
    "        self._gamma = gamma\n",
    "        self._deg = deg\n",
    "        self._r = r\n",
    "        self._c = c\n",
    "        self._svm_list = []\n",
    "        self._labels = None\n",
    "        self._support_vectors = set()\n",
    "\n",
    "    def fit(self, x: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\"Fit the SVM on the given training set.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : ndarray\n",
    "            Training data with shape (n_samples, n_features).\n",
    "        y : ndarray\n",
    "            Ground-truth labels.\n",
    "        \"\"\"\n",
    "        # Check if labels are integers\n",
    "        labels = np.unique(y)\n",
    "        for label in labels:\n",
    "            if not label.is_integer():\n",
    "                raise ValueError(str(label) + \" is not an integer value label\")\n",
    "        self._labels = np.array(labels, dtype=int)\n",
    "\n",
    "        # Re-arrange training set per labels in a dictionary\n",
    "        x_arranged_list = collections.defaultdict(list)\n",
    "        for index, x_ in enumerate(x):\n",
    "            x_arranged_list[y[index]].append(x_)\n",
    "\n",
    "        # Convert to numpy array the previous dictionary\n",
    "        x_arranged_numpy = {}\n",
    "        for index in range(len(self._labels)):\n",
    "            x_arranged_numpy[index] = np.array(x_arranged_list[index])\n",
    "\n",
    "        for i in range(0, self._labels.shape[0] - 1):\n",
    "            for j in range(i + 1, self._labels.shape[0]):\n",
    "                current_x = np.concatenate((x_arranged_numpy[i], x_arranged_numpy[j]))\n",
    "                current_y = np.concatenate((- np.ones((len(x_arranged_numpy[i]),), dtype=int),\n",
    "                                           np.ones(len((x_arranged_numpy[j]),), dtype=int)))\n",
    "                svm = SVM(kernel=self._kernel, gamma=self._gamma, deg=self._deg, r=self._r, c=self._c)\n",
    "                svm.fit(current_x, current_y, verbosity=0)\n",
    "                for sv in svm.sv_x:\n",
    "                    self._support_vectors.add(tuple(sv.tolist()))\n",
    "                svm_tuple = (svm, self._labels[i], self._labels[j])\n",
    "                self._svm_list.append(svm_tuple)\n",
    "        print('{0:d} support vectors found out of {1:d} data points'.format(len(self._support_vectors), len(x)))\n",
    "\n",
    "    def predict(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Predict the class of the given data points. The voting process is based on the standard predict function\n",
    "        for binary SVM classifiers, so the input entry is assigned to the class which wins the highest number of binary\n",
    "        comparisons; to counteract the possible risk of draw, the predicted value before the application of the \"sign\"\n",
    "        function in binary classifiers is stored as well.\n",
    "        For each sample j, for each label i:\n",
    "            - voting_schema[j][0][i] is the number of total comparisons won\n",
    "            - voting_schema[j][1][i] is the cumulative sum of predicted values\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : ndarray\n",
    "            Data points with shape (n_samples, n_features).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ndarray\n",
    "            Results of the voting scheme.\n",
    "        \"\"\"\n",
    "        voting_schema = np.zeros([len(x), 2, self._labels.shape[0]], dtype=float)\n",
    "        for svm_tuple in self._svm_list:\n",
    "            prediction = svm_tuple[0].project(x)\n",
    "            for i in range(len(prediction)):\n",
    "                if prediction[i] < 0:\n",
    "                    voting_schema[i][0][svm_tuple[1]] += 1\n",
    "                    voting_schema[i][1][svm_tuple[1]] += -1 * prediction[i]\n",
    "                else:\n",
    "                    voting_schema[i][0][svm_tuple[2]] += 1\n",
    "                    voting_schema[i][1][svm_tuple[2]] += prediction[i]\n",
    "\n",
    "        voting_results = np.zeros(len(voting_schema), dtype=int)\n",
    "        for i in range(len(voting_schema)):\n",
    "            sorted_votes = np.sort(voting_schema[i][0])\n",
    "            # If the first two classes received a different number of votes there is no draw\n",
    "            if sorted_votes[0] > sorted_votes[1]:\n",
    "                voting_results[i] = voting_schema[i][0].argmax()\n",
    "            # Otherwise return label of the class which has the highest cumulative sum of predicted values\n",
    "            else:\n",
    "                voting_results[i] = voting_schema[i][1].argmax()\n",
    "\n",
    "        return voting_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C3S1' 'C2S1' 'C3S2' 'C4S1' 'C4S2' 'C1S1' 'C4S3' 'C4S4' 'C3S3' 'OG'\n",
      " 'C3S4' 'BELOW THE GRAPH' 'O.G' 'OUT OF SAR GRAPH' 'C2S2' 'BG']\n",
      "['C3S1' 'C2S1' 'C3S2' 'C4S1' 'C4S2' 'C1S1' 'C4S3' 'C4S4' 'C3S3' 'C3S4'\n",
      " 'C2S2']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4907 entries, 0 to 4906\n",
      "Data columns (total 17 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   pH              4907 non-null   float64\n",
      " 1   E.C             4907 non-null   float64\n",
      " 2   TDS             4907 non-null   float64\n",
      " 3   CO3             4907 non-null   float64\n",
      " 4   HCO3            4907 non-null   float64\n",
      " 5   Cl              4907 non-null   float64\n",
      " 6   F               4907 non-null   float64\n",
      " 7   NO3             4907 non-null   float64\n",
      " 8   SO4             4907 non-null   float64\n",
      " 9   Na              4907 non-null   float64\n",
      " 10  K               4907 non-null   float64\n",
      " 11  Ca              4907 non-null   float64\n",
      " 12  Mg              4907 non-null   float64\n",
      " 13  T.H             4907 non-null   float64\n",
      " 14  SAR             4907 non-null   float64\n",
      " 15  RSC  meq  / L   4907 non-null   float64\n",
      " 16  Classification  4907 non-null   object \n",
      "dtypes: float64(16), object(1)\n",
      "memory usage: 651.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from dataset import load_dataset\n",
    "\n",
    "dataset_df = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification\n",
      "1     3107\n",
      "0     1169\n",
      "3      238\n",
      "2      148\n",
      "4      112\n",
      "7       52\n",
      "5       26\n",
      "6       25\n",
      "9       23\n",
      "8        6\n",
      "10       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset_df['Classification'] = dataset_df['Classification'].map({'C2S1': 0, 'C3S1': 1, 'C4S2': 2, 'C4S1': 3, 'C3S2': 4\n",
    "                                                                 , 'C4S4': 5, 'C4S3': 6, 'C1S1': 7, 'C3S4': 8, 'C3S3': 9, 'C2S2': 10}).astype(int)\n",
    "input_X = dataset_df.drop(columns=['Classification'])\n",
    "input_y = dataset_df['Classification']\n",
    "print(input_y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_X, input_y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_svm = MulticlassSVM(kernel=\"rbf\", c=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498 support vectors found out of 3287 data points\n"
     ]
    }
   ],
   "source": [
    "multi_svm.fit(X_train.to_numpy(), y_train.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.32098765432099\n"
     ]
    }
   ],
   "source": [
    "multi_svm_predictions = multi_svm.predict(X_test.to_numpy())\n",
    "print(np.sum(y_test == multi_svm_predictions)/len(y_test) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.1604938271605\n",
      "875 support vectors found out of 3287 data points\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel=\"rbf\",gamma=\"scale\", decision_function_shape=\"ovo\")\n",
    "svc.fit(X_train, y_train)\n",
    "svc_predictions = svc.predict(X_test)\n",
    "print(np.sum(y_test == svc_predictions)/len(y_test) * 100)\n",
    "print(f\"{len(svc.support_):d} support vectors found out of {len(X_train):d} data points\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
